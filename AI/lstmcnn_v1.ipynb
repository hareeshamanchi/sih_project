{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46208051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# GPU?\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae37a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file from the project root\n",
    "load_dotenv(dotenv_path=\"AI/.env\")  # adjust path if notebook is in /notebooks\n",
    "\n",
    "OPENWEATHER_API_KEY = os.getenv(\"OPENWEATHER_API_KEY\")\n",
    "print(\"API key loaded:\", OPENWEATHER_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb17f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# === CONFIG ===\n",
    "CSV_PATH = \"AI/synthetic_dataset (1).csv\"   # path to your CSV\n",
    "WINDOW = 14           \n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-3\n",
    "EPOCHS = 80\n",
    "PATIENCE = 8         \n",
    "\n",
    "FEATURE_COLS = [\"temp\", \"humidity\", \"rainfall\", \"wqi\", \"diarrhea\", \"cholera\", \"typhoid\"]\n",
    "TARGET_COLS = [\"diarrhea\", \"cholera\", \"typhoid\"]\n",
    "MODEL_OUT = \"cnn_lstm_best.pth\"\n",
    "SEED = 42\n",
    "\n",
    "# ðŸ”‘ Load API key from .env file\n",
    "load_dotenv()\n",
    "OPENWEATHER_API_KEY = os.getenv(\"OPENWEATHER_API_KEY\")\n",
    "print(\"OPENWEATHER_API_KEY loaded:\", OPENWEATHER_API_KEY is not None)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "df = pd.read_csv(CSV_PATH, parse_dates=[\"Date\"], dayfirst=True, infer_datetime_format=True)\n",
    "df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "df[FEATURE_COLS] = df[FEATURE_COLS].apply(pd.to_numeric, errors='coerce').fillna(0.0)\n",
    "df[TARGET_COLS] = df[TARGET_COLS].astype(int)\n",
    "\n",
    "# Add difference features\n",
    "for col in [\"temp\", \"humidity\", \"rainfall\"]:\n",
    "    df[f\"{col}_diff\"] = df[col].diff().fillna(0)\n",
    "\n",
    "FEATURE_COLS_EXT = FEATURE_COLS + [f\"{col}_diff\" for col in [\"temp\", \"humidity\", \"rainfall\"]]\n",
    "\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())\n",
    "print(\"\\nFeature columns:\", FEATURE_COLS_EXT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e02dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, target_cols, window=WINDOW, scaler_x=None, scaler_y=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_cols = target_cols\n",
    "        self.window = window\n",
    "\n",
    "        X = self.df[self.feature_cols].values.astype(np.float32)\n",
    "        Y = self.df[self.target_cols].values.astype(np.float32)\n",
    "\n",
    "        self.scaler_x = MinMaxScaler() if scaler_x is None else scaler_x\n",
    "        self.scaler_y = MinMaxScaler() if scaler_y is None else scaler_y\n",
    "        if scaler_x is None:\n",
    "            self.scaler_x.fit(X)\n",
    "        if scaler_y is None:\n",
    "            self.scaler_y.fit(Y)\n",
    "\n",
    "        Xs = self.scaler_x.transform(X)\n",
    "        Ys = self.scaler_y.transform(Y)\n",
    "\n",
    "        self.samples = []\n",
    "        for i in range(window, len(self.df)):\n",
    "            x_win = Xs[i-window:i]\n",
    "            y_target = Ys[i]\n",
    "            self.samples.append((x_win.astype(np.float32), y_target.astype(np.float32)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.samples[idx]\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aac5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "n = len(df)\n",
    "train_end = int(0.7 * n)\n",
    "val_end = int(0.85 * n)\n",
    "\n",
    "df_train = df.iloc[:train_end].reset_index(drop=True)\n",
    "df_val = df.iloc[train_end - WINDOW:val_end].reset_index(drop=True)\n",
    "df_test = df.iloc[val_end - WINDOW:].reset_index(drop=True)\n",
    "\n",
    "train_ds = SeqDataset(df_train, FEATURE_COLS_EXT, TARGET_COLS, window=WINDOW)\n",
    "val_ds = SeqDataset(df_val, FEATURE_COLS_EXT, TARGET_COLS, window=WINDOW,\n",
    "                    scaler_x=train_ds.scaler_x, scaler_y=train_ds.scaler_y)\n",
    "test_ds = SeqDataset(df_test, FEATURE_COLS_EXT, TARGET_COLS, window=WINDOW,\n",
    "                     scaler_x=train_ds.scaler_x, scaler_y=train_ds.scaler_y)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "print(\"Dataset sizes:\", len(train_ds), len(val_ds), len(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570bbdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, n_features, cnn_channels=64, lstm_hidden=128, lstm_layers=1, out_dim=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(cnn_channels, cnn_channels*2, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(cnn_channels*2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(cnn_channels*2, cnn_channels*4, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels*4)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=cnn_channels*4, hidden_size=lstm_hidden,\n",
    "                            num_layers=lstm_layers, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)   # (batch, features, seq)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = x.permute(0, 2, 1)   # (batch, seq, features)\n",
    "        x, _ = self.lstm(x)\n",
    "        out = x[:, -1, :]\n",
    "        return self.fc(out)\n",
    "\n",
    "model = CNNLSTM(n_features=len(FEATURE_COLS_EXT), out_dim=len(TARGET_COLS)).to(DEVICE)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfdbe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def train_model_full_epochs(model, train_loader, val_loader, epochs=EPOCHS, lr=LR):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=4)\n",
    "    best_val = 1e9\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for Xv, yv in val_loader:\n",
    "                Xv, yv = Xv.to(DEVICE), yv.to(DEVICE)\n",
    "                pv = model(Xv)\n",
    "                val_losses.append(criterion(pv, yv).item())\n",
    "\n",
    "        train_loss, val_loss = np.mean(train_losses), np.mean(val_losses)\n",
    "        scheduler.step(val_loss)\n",
    "        print(f\"Epoch {epoch}: Train {train_loss:.6f}, Val {val_loss:.6f}\")\n",
    "\n",
    "        # Save model if validation improves\n",
    "        if val_loss < best_val - 1e-6:\n",
    "            best_val = val_loss\n",
    "            torch.save(model.state_dict(), MODEL_OUT)\n",
    "            print(f\"  Saved best model at epoch {epoch}\")\n",
    "\n",
    "    model.load_state_dict(torch.load(MODEL_OUT, map_location=DEVICE))\n",
    "    return model\n",
    "\n",
    "# Train model for all epochs\n",
    "model = train_model_full_epochs(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39763afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def classify_risk(disease, value):\n",
    "    thresholds = {\n",
    "        \"diarrhea\": {\"low\": 30, \"medium\": 60},\n",
    "        \"cholera\": {\"low\": 50, \"medium\": 80},\n",
    "        \"typhoid\": {\"low\": 20, \"medium\": 40}\n",
    "    }\n",
    "    \n",
    "    if value <= thresholds[disease][\"low\"]:\n",
    "        return \"LOW âœ… â€” normal levels\"\n",
    "    elif value <= thresholds[disease][\"medium\"]:\n",
    "        return \"MEDIUM âš ï¸ â€” monitor closely\"\n",
    "    else:\n",
    "        return \"HIGH ðŸš¨ â€” take preventive measures\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63086354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def predict_next_day(model, df_recent, lat, lon):\n",
    "    \"\"\"Use live weather + model to predict next-day diseases\"\"\"\n",
    "    try:\n",
    "        weather_data = requests.get(\n",
    "            f\"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
    "        ).json()\n",
    "        if \"main\" not in weather_data:\n",
    "            raise ValueError(\"Weather API returned no 'main'\")\n",
    "        live_weather = {\n",
    "            'temp': round(weather_data['main']['temp'], 2),\n",
    "            'humidity': round(weather_data['main']['humidity'], 2),\n",
    "            'rainfall': round(weather_data.get('rain', {}).get('1h', 0), 2)\n",
    "        }\n",
    "        print(\"Weather API raw response:\", weather_data)\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ Weather API failed:\", e)\n",
    "        live_weather = {\n",
    "            'temp': df_recent['temp'].iloc[-1],\n",
    "            'humidity': df_recent['humidity'].iloc[-1],\n",
    "            'rainfall': df_recent['rainfall'].iloc[-1]\n",
    "        }\n",
    "\n",
    "    df_next = df_recent.copy()\n",
    "    df_next['temp_diff'] = df_next['temp'].diff().fillna(0)\n",
    "    df_next['humidity_diff'] = df_next['humidity'].diff().fillna(0)\n",
    "    df_next['rainfall_diff'] = df_next['rainfall'].diff().fillna(0)\n",
    "\n",
    "    df_next.iloc[-1, df_next.columns.get_loc('temp')] = live_weather['temp']\n",
    "    df_next.iloc[-1, df_next.columns.get_loc('humidity')] = live_weather['humidity']\n",
    "    df_next.iloc[-1, df_next.columns.get_loc('rainfall')] = live_weather['rainfall']\n",
    "\n",
    "    df_next.iloc[-1, df_next.columns.get_loc('temp_diff')] = df_next['temp'].iloc[-1] - df_next['temp'].iloc[-2]\n",
    "    df_next.iloc[-1, df_next.columns.get_loc('humidity_diff')] = df_next['humidity'].iloc[-1] - df_next['humidity'].iloc[-2]\n",
    "    df_next.iloc[-1, df_next.columns.get_loc('rainfall_diff')] = df_next['rainfall'].iloc[-1] - df_next['rainfall'].iloc[-2]\n",
    "\n",
    "    X_next = df_next[FEATURE_COLS_EXT].values.astype(np.float32)\n",
    "    X_next_scaled = train_ds.scaler_x.transform(X_next)\n",
    "    X_next_tensor = torch.tensor(X_next_scaled).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_scaled = model(X_next_tensor).cpu().numpy()\n",
    "\n",
    "    pred = train_ds.scaler_y.inverse_transform(pred_scaled)[0]\n",
    "    # Round predictions to integer\n",
    "    pred_int = [int(round(p)) for p in pred]\n",
    "    result = {col: pred_int[i] for i, col in enumerate(TARGET_COLS)}\n",
    "    result.update(live_weather)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5acecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "recent_df = df.iloc[-WINDOW:].copy()\n",
    "next_day_pred = predict_next_day(model, recent_df, lat=13.6576 , lon=78.2624)\n",
    "\n",
    "print(\"ðŸŒ Next-day Disease Forecast with Risk Alerts\")\n",
    "for disease in [\"diarrhea\", \"cholera\", \"typhoid\"]:\n",
    "    value = next_day_pred[disease]\n",
    "    alert = classify_risk(disease, value)\n",
    "    print(f\"{disease.capitalize()}: {value} cases â†’ {alert}\")\n",
    "\n",
    "print(f\"\\nWeather Conditions: ðŸŒ¡ï¸ {next_day_pred['temp']}Â°C, ðŸ’§ {next_day_pred['humidity']}%, ðŸŒ§ï¸ {next_day_pred['rainfall']}mm\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
